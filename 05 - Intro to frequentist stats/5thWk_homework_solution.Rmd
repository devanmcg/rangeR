---
title: "Analysis of Ecosystems homework week 5"
subtitle: "Intro to statistical inference"
date: "`r format(Sys.time(), '%d %B %Y')`"
author: "The solution"
header-includes:
   - \usepackage{nicefrac}
output: pdf_document
---

```{r chunk1, echo=FALSE, results='hide', message=FALSE}
# DOn't mess with this chunk
knitr::opts_chunk$set(message = FALSE, warning=FALSE, echo=TRUE, eval=TRUE, fig.align = 'center')
if (!require("pacman")) install.packages("pacman")
```

```{r chunk2, echo=TRUE, results='hide'}
pacman::p_load(s20x, pander, plyr, tidyverse, gridExtra)
```

# Data preparation 

```{r chunk3, echo=FALSE, results='verbatim'}
# R code chunk 3: Add columns
mpg <- mpg %>%
  mutate(trans = ifelse((substring(trans,1,4)=='auto'),'auto', 'manual'), 
         origin = as.factor(revalue(manufacturer, 
                                c("audi"="Foreign","chevrolet"="USA",
                                  "dodge"="USA", "ford"="USA","jeep"="USA", 
                                  "honda"="Foreign", "hyundai"="Foreign",
                                  "land rover"="Foreign","subaru"="Foreign", 
                                  "lincoln"="USA", "mercury"="USA", 
                                  "nissan"="Foreign", "pontiac"="USA", 
                                  "toyota"="Foreign","volkswagen"="Foreign")) ) ) 
str(mpg)
```

# The t test

## Assumptions


* \textsf{Independent samples}
* \textsf{Normal distribution}
* \textsf{Equal variance within groups}


## Distribution 

### Graphing


```{r chunk4, fig.height = 6, fig.cap="TOP: Distribution of the \\texttt{cty} variable, before log transformation (L) and after log transformation (R). BOTTOM: Q-Q plots for the above. \\label{dist}"}
# Distribution plots
  raw.d.gg <-
    ggplot(mpg, aes(x=cty)) + theme_bw(14) + 
      geom_histogram(aes(y=..density..),      
                     binwidth=1,
                     colour="black", fill="lightgreen") +
      geom_density(alpha=0.2, fill="lightgreen") +
      stat_function(data=mpg, 
                          fun = dnorm, 
                          args=list(mean=mean(mpg$cty),    
                                      sd=sd(mpg$cty)),    
                          colour="blue", size=1.1) 
  log.d.gg <-
    ggplot(mpg, aes(x=log(cty))) + theme_bw(16) + 
      geom_histogram(aes(y=..density..),      
                     binwidth=0.1,
                     colour="black", fill="lightgreen") +
      geom_density(alpha=0.2, fill="lightgreen") +
      stat_function(data=mpg, 
                          fun = dnorm, 
                          args=list(mean=mean(log(mpg$cty)),    
                                      sd=sd(log(mpg$cty))),    
                          colour="blue", size=1.1) 
# Q-Q plots 
  raw.QQ.gg <- 
         ggplot(mpg, aes(sample=cty)) + theme_bw(14) +
            stat_qq(size=4,  bg="#43a2ca", col="black", pch=21) +
            stat_qq_line(size=1.5, color="blue")
  log.QQ.gg <- 
         ggplot(mpg, aes(sample=log(cty))) + theme_bw(14) +
            stat_qq(size=4, bg="#43a2ca", col="black", pch=21) +
            stat_qq_line(size=1.5, color="blue")

grid.arrange(raw.d.gg,  log.d.gg, 
             raw.QQ.gg, log.QQ.gg, nrow = 2)
```

### Interpretation

\textsf{The untransformed data are skewed right (Fig. \ref{dist}), but log transformation improves the fit between the distribution of the \texttt{cty} variable and the theoretical normal distribution. QQ plot of the log transformed data confirm the better fit. }

## Variance

### Test

One option is the base \texttt{var.test}:

```{r chunkVT}
vt <- var.test(log(cty) ~ origin, mpg, ratio=1) 
pander(vt)
```

Another option is a Bartlett's test using the \texttt{ols_test_bartlett} function in the \texttt{olsrr} package:

```{r chunkBT}
mpg$Lcty <- log(mpg$cty)
olsrr::ols_test_bartlett(mpg, Lcty, group_var = origin)
```

### Interpretation

\textsf{The variance ratio of the log transformed \texttt{cty} variable among the two \texttt{origin} groups is 1.2, and not statistically different than 1. Thus these data meet the assumption of equal variance. }

# The linear model

## Assumptions

* \textsf{Linear relationship between variables}
* \textsf{Independent samples}
* \textsf{Normal distribution}
* \textsf{\emph{Homoscedasticity}\textendash Homogeneous variance along regression gradient}

## Distribution 

### Graphing

\textsf{Figure \ref{dist} already shows us that the \texttt{cty} variable meets the assumptions of normality. To test the unique assumption of the linear model\textemdash equal variance along the regression gradient\textemdash we can look at the residuals of the regression model. This requires us to fit the model to assess the assumption. In a sense, then, homoscedasticity is more of an assumption of the \emph{model results} than of the data themselves, although obviously the model results are unique to the data.} 

```{r chunk6, out.width = '50%', fig.cap="Residual plot for the linear model fitting \\texttt{cty} against \\texttt{displ}. \\label{resid} "}
m1 <- lm(log(cty) ~ displ, mpg) 
ggplot(m1) + theme_bw(24) +
  geom_hline(yintercept = 0, size=1.5) + 
  geom_smooth(aes(x=.fitted, y=.resid), 
              color="red", se=FALSE) +
  geom_smooth(aes(x=.fitted, y=.resid), se=FALSE,
              method="lm", color="lightblue", lty=2 ) + 
  geom_point(aes(x=.fitted, y=.resid), size=4,
             bg="#43a2ca", col="black", pch=21)
```

### Statistical tests 

\textsf{Several statistical procedures test the alternative hypothesis that variance is not constant. The \texttt{car} package gives us a test for non-constant variance, typically known also as a \emph{Breusch-Pagan} test, although the \texttt{car} formulation returns a $\chi^2$ test statistic: }


```{r NCV} 
car::ncvTest(m1)
```

\textsf{The \texttt{lmtest} package also provides a function to perform a Breusch-Pagan test, \texttt{bptest} :}

```{r BPtest}
lmtest::bptest(m1)
```


\textsf{Finally, package \texttt{olsrr} includes several tests for heteroscedasticity; here we run an F test:} 

```{r chunkFT}

olsrr::ols_test_f(m1)
```


\textsf{These data fail each test. What can be done about non-constant variance, or heteroscedasticity? The conventional approach is a \emph{Box-Cox transformation}:}


```{r BCt} 
caret::BoxCoxTrans(mpg$Lcty)


```

\textsf{The Box-Cox transformation actually suggested we are within the ``fudge factor'' and should not perform the transformation. So we won't. (In my view this is the best approach. I like a procedure that doesn't feel like it has to do something, and clearly lets us know when we're within the margins of acceptability and don't need to change anything. I don't like to depend on a P value.)}

### Interpretation

\textsf{The previous log transformation took care of our normality assumption. The residual plot (Fig. \ref{resid}) is ok but not great\textemdash a linear regression fit to the residuals has $\beta_0$ = 0, which is good (blue broken line in Fig. \ref{resid}), but there is some curvilinearity at the lowest end of the plot (red line in Fig. \ref{resid}). }

## Fit a linear model

### Test

```{r chunk7}
anova(m1) %>%
  pander(.)
```

### Plot

```{r chunk8, out.width='50%', fig.cap="The linear relationship between \\texttt{cty} and \\texttt{displ}, the former log transformed. \\label{lm}"}

ggplot(mpg, aes(x=displ, y=log(cty))) + theme_bw(20) + 
  geom_smooth(se=FALSE, method="lm", 
              size=1.5, color="blue") + 
  geom_point(size=4,  pch=21,
             bg="#43a2ca", col="black") +
  labs(x="Engine size (L)", 
       y="City fuel economy\n(log mpg)")
  


```

## Evaluate the linear model

### Model fit

```{r chunk9, results='verbatim', fig=TRUE}
summary(m1)

```


\textsf{The model fits the data well, explaining about 71\% of variation between the variables as determined by \emph{R}\textsuperscript{2}=0.71.}

### Model results

* Degrees of freedom: \textsf{232}
* Total Sum of Squares: \textsf{14.5} 
* Test statistic for the overall model: \textsf{\emph{F}\textsubscript{\nicefrac{1}{232}}=573.8}
* Test statistic for the dependent variable: \textsf{\emph{t} = -21.8}
* Results of significance test: \textsf{\emph{P} < 0.001}

### Interpretation

\textsf{There is a strong negative linear relationship between \texttt{cty} and \texttt{displ}, indicating that in general, as engine size increases, fuel economy declines.} 

